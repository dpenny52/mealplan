---
phase: 05-ai-features
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - package.json
  - convex/ai.ts
  - src/contexts/WizardContext.tsx
  - .env.local (reference only - user adds GEMINI_API_KEY)
autonomous: true
user_setup:
  - service: gemini
    why: "AI-powered recipe extraction"
    env_vars:
      - name: GEMINI_API_KEY
        source: "Google AI Studio -> Get API key -> Create API key"
        target: "Convex Dashboard -> Settings -> Environment Variables"

must_haves:
  truths:
    - "Gemini SDK is installed and accessible from Convex actions"
    - "Recipe extraction action exists and returns structured JSON"
    - "WizardContext can store extraction confidence data"
  artifacts:
    - path: "convex/ai.ts"
      provides: "Gemini extraction action"
      exports: ["extractRecipeFromImage"]
    - path: "src/contexts/WizardContext.tsx"
      provides: "Extended wizard state with confidence"
      contains: "extractionConfidence"
  key_links:
    - from: "convex/ai.ts"
      to: "@google/genai"
      via: "GoogleGenAI import"
      pattern: "GoogleGenAI"
---

<objective>
Set up Gemini AI backend infrastructure for recipe extraction

Purpose: Establish the foundation for AI-powered recipe photo extraction - install dependencies, create the Convex action that calls Gemini, and extend the wizard context to store extraction metadata.

Output: Working Gemini action that accepts base64 image and returns structured recipe data with confidence scores, plus updated WizardContext ready for extraction flow.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-ai-features/05-CONTEXT.md
@.planning/phases/05-ai-features/05-RESEARCH.md

# Existing files to extend
@src/contexts/WizardContext.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install AI dependencies</name>
  <files>package.json</files>
  <action>
Install the required packages for Gemini AI integration:

```bash
npm install @google/genai zod zod-to-json-schema --legacy-peer-deps
npx expo install expo-camera
```

Dependencies:
- @google/genai: Official Google Gemini SDK (NOT deprecated @google/generative-ai)
- zod: Schema validation for structured AI output
- zod-to-json-schema: Convert Zod schemas to JSON schema for Gemini
- expo-camera: Custom camera UI with overlay support

Note: Use --legacy-peer-deps per project convention (React version conflict with Convex).
  </action>
  <verify>
Run `npm ls @google/genai zod expo-camera` - all packages should be listed without errors.
  </verify>
  <done>@google/genai, zod, zod-to-json-schema, and expo-camera are in package.json dependencies</done>
</task>

<task type="auto">
  <name>Task 2: Create Gemini extraction action</name>
  <files>convex/ai.ts</files>
  <action>
Create a new Convex action file for Gemini API calls. CRITICAL: This file MUST have "use node" directive at the top - Gemini SDK requires Node runtime, and mixing with queries/mutations in same file causes build errors.

File: convex/ai.ts

```typescript
"use node";
import { action } from "./_generated/server";
import { v } from "convex/values";
import { GoogleGenAI } from "@google/genai";
import { z } from "zod";
import { zodToJsonSchema } from "zod-to-json-schema";

/**
 * Zod schema for extracted recipe data.
 * Includes confidence scores per field for UI highlighting.
 */
const extractedRecipeSchema = z.object({
  title: z.string().describe("Recipe name/title"),
  titleConfidence: z.number().min(0).max(1).describe("Confidence in title extraction"),
  ingredients: z.array(z.object({
    text: z.string().describe("Full ingredient line, e.g., '2 cups flour'"),
    confidence: z.number().min(0).max(1).describe("Confidence in this ingredient"),
  })).describe("List of ingredients with quantities"),
  instructions: z.string().optional().describe("Cooking instructions/steps"),
  instructionsConfidence: z.number().min(0).max(1).optional().describe("Confidence in instructions"),
  servings: z.number().optional().describe("Number of servings if mentioned"),
  prepTimeMinutes: z.number().optional().describe("Prep/cook time in minutes if mentioned"),
});

export type ExtractedRecipe = z.infer<typeof extractedRecipeSchema>;

/**
 * Extract recipe details from an image using Gemini AI.
 * Returns structured data with confidence scores.
 */
export const extractRecipeFromImage = action({
  args: {
    imageBase64: v.string(),
    mimeType: v.string(), // "image/jpeg" or "image/png"
  },
  returns: v.object({
    success: v.boolean(),
    recipe: v.optional(v.any()), // ExtractedRecipe when success=true
    error: v.optional(v.string()),
  }),
  handler: async (ctx, args) => {
    const apiKey = process.env.GEMINI_API_KEY;
    if (!apiKey) {
      return { success: false, error: "Gemini API key not configured" };
    }

    try {
      const ai = new GoogleGenAI({ apiKey });

      const response = await ai.models.generateContent({
        model: "gemini-2.5-flash",
        contents: [
          {
            inlineData: {
              mimeType: args.mimeType,
              data: args.imageBase64,
            },
          },
          `Extract the recipe from this image. Return structured JSON with:
- title: The recipe name
- titleConfidence: Your confidence in the title (0-1)
- ingredients: Array of {text, confidence} for each ingredient line (include quantity and unit)
- instructions: The cooking instructions (if visible)
- instructionsConfidence: Confidence in instructions (if included)
- servings: Number of servings (if mentioned)
- prepTimeMinutes: Prep/cook time in minutes (if mentioned)

Confidence scoring guidelines:
- 0.9-1.0: Clearly legible, unambiguous text
- 0.7-0.9: Mostly readable, minor uncertainty
- 0.5-0.7: Partially visible or unclear, some guessing involved
- Below 0.5: Heavily inferred or guessed

Be generous with confidence scores for clearly legible text.`,
        ],
        config: {
          responseMimeType: "application/json",
          responseJsonSchema: zodToJsonSchema(extractedRecipeSchema),
        },
      });

      const text = response.text;
      if (!text) {
        return { success: false, error: "Empty response from AI" };
      }

      const parsed = JSON.parse(text);
      return { success: true, recipe: parsed };
    } catch (error) {
      console.error("Gemini extraction error:", error);
      const message = error instanceof Error ? error.message : "Unknown extraction error";
      return { success: false, error: message };
    }
  },
});
```

Key design decisions:
- "use node" directive MUST be on line 1 (Convex requirement for Node-only code)
- Returns {success, recipe?, error?} pattern for clean error handling
- Includes confidence scores per field as requested in CONTEXT.md
- Uses gemini-2.5-flash (fast, sufficient for OCR, higher rate limits than Pro)
- API key read from Convex environment variables (not client-side)
  </action>
  <verify>
Run `npx convex dev` - should compile without errors. The action won't be callable yet until user adds GEMINI_API_KEY to Convex env vars.
  </verify>
  <done>convex/ai.ts exists with extractRecipeFromImage action that accepts base64 image and returns structured recipe data with confidence scores</done>
</task>

<task type="auto">
  <name>Task 3: Extend WizardContext for extraction data</name>
  <files>src/contexts/WizardContext.tsx</files>
  <action>
Extend the existing WizardContext to store extraction confidence data and original photo URI. The wizard will be reused for review/edit of extracted recipes.

Update WizardData interface to add:
```typescript
// Add to WizardData interface:
extractionConfidence?: {
  titleConfidence: number;
  ingredients: Array<{ text: string; confidence: number }>;
  instructionsConfidence?: number;
};
originalPhotoUri?: string; // For "view original" button in review
```

Changes:
1. Add extractionConfidence field (optional) to WizardData interface - stores per-field confidence
2. Add originalPhotoUri field (optional) - stores the photo URI for review screen
3. Update initialData to include undefined for both new fields
4. NO changes needed to WizardProvider or useWizard - Partial<WizardData> in updateData handles new fields automatically

The extraction flow will call updateData() to populate these fields before navigating to the wizard.
  </action>
  <verify>
TypeScript compiles without errors: `npx tsc --noEmit`
  </verify>
  <done>WizardContext supports extractionConfidence and originalPhotoUri fields, enabling the scan flow to pre-populate the wizard with extracted data</done>
</task>

</tasks>

<verification>
1. `npm ls @google/genai zod expo-camera` shows all packages installed
2. `npx convex dev` compiles without errors
3. `npx tsc --noEmit` passes with no type errors
4. convex/ai.ts has "use node" on first line
5. WizardData type includes extractionConfidence and originalPhotoUri
</verification>

<success_criteria>
- All dependencies installed (check package.json)
- Convex action compiles and is ready for use (pending API key)
- WizardContext extended for extraction flow
- No TypeScript or build errors
</success_criteria>

<output>
After completion, create `.planning/phases/05-ai-features/05-01-SUMMARY.md`
</output>
